{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import numpy as np\\nimport pandas as pd\\n\\nfrom matplotlib import pyplot as plt\\nimport tensorflow as tf\\n\\n from keras.preprocessing.image import load_img\\n\\nimport keras.backend as K\\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping\\n\\nfrom tensorflow.keras.models import Model\\nfrom tensorflow.keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, BatchNormalization\\n\\nfrom skimage.data import imread\\nfrom skimage.transform import resize\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load truncated iamges https://www.kaggle.com/c/airbus-ship-detection/discussion/62574#latest-445141\\nfrom PIL import ImageFile\\nImageFile.LOAD_TRUNCATED_IMAGES = True'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    " from keras.preprocessing.image import load_img\n",
    "\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, BatchNormalization\n",
    "\n",
    "from skimage.data import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load truncated iamges https://www.kaggle.com/c/airbus-ship-detection/discussion/62574#latest-445141\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Variables\n",
    "IMG_WIDTH = 768\n",
    "IMG_HEIGHT = 768\n",
    "IMG_CHANNELS = 3\n",
    "TARGET_WIDTH = 128\n",
    "TARGET_HEIGHT = 128\n",
    "epochs=1\n",
    "batch_size=10\n",
    "image_shape=(768, 768)\n",
    "FAST_RUN=False # use for development only\n",
    "FAST_PREDICTION=False # use for development only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Data\n",
    "df = pd.read_csv(\"../input/train_ship_segmentations_v2.csv\")\n",
    "sub_df = pd.read_csv(\"../input/sample_submission_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore Data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_mask = np.zeros(image_shape[0]*image_shape[1], dtype=np.uint8)\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    rle = ' '.join(str(x) for x in runs)\n",
    "    return rle\n",
    "\n",
    "def rle_decode(mask_rle, shape=image_shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    if pd.isnull(mask_rle):\n",
    "        img = no_mask\n",
    "        return img.reshape(shape).T\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image With Ship\n",
    "\n",
    "segmentation = df[df.EncodedPixels.notnull()].sample().iloc[0]\n",
    "image = imread('../input/train_v2/'+segmentation.ImageId)\n",
    "\n",
    "fig=plt.figure(figsize=(16, 8))\n",
    "fig.add_subplot(2, 2, 1)\n",
    "plt.imshow(image)\n",
    "fig.add_subplot(2, 2, 2)\n",
    "plt.imshow(rle_decode(segmentation.EncodedPixels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image without ship\n",
    "segmentation = df[df.EncodedPixels.isnull()].sample().iloc[0]\n",
    "image = imread('../input/train_v2/'+segmentation.ImageId)\n",
    "\n",
    "fig=plt.figure(figsize=(16, 8))\n",
    "fig.add_subplot(2, 2, 1)\n",
    "plt.imshow(image)\n",
    "fig.add_subplot(2, 2, 2)\n",
    "plt.imshow(rle_decode(segmentation.EncodedPixels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define U-Net Model\n",
    "\n",
    "inputs = Input((TARGET_WIDTH , TARGET_HEIGHT, IMG_CHANNELS))\n",
    "\n",
    "# 128\n",
    "\n",
    "down1 = Conv2D(64, (3, 3), padding='same')(inputs)\n",
    "down1 = BatchNormalization()(down1)\n",
    "down1 = Activation('relu')(down1)\n",
    "down1 = Conv2D(64, (3, 3), padding='same')(down1)\n",
    "down1 = BatchNormalization()(down1)\n",
    "down1 = Activation('relu')(down1)\n",
    "down1_pool = MaxPooling2D((2, 2), strides=(2, 2))(down1)\n",
    "# 64\n",
    "\n",
    "down2 = Conv2D(128, (3, 3), padding='same')(down1_pool)\n",
    "down2 = BatchNormalization()(down2)\n",
    "down2 = Activation('relu')(down2)\n",
    "down2 = Conv2D(128, (3, 3), padding='same')(down2)\n",
    "down2 = BatchNormalization()(down2)\n",
    "down2 = Activation('relu')(down2)\n",
    "down2_pool = MaxPooling2D((2, 2), strides=(2, 2))(down2)\n",
    "# 32\n",
    "\n",
    "down3 = Conv2D(256, (3, 3), padding='same')(down2_pool)\n",
    "down3 = BatchNormalization()(down3)\n",
    "down3 = Activation('relu')(down3)\n",
    "down3 = Conv2D(256, (3, 3), padding='same')(down3)\n",
    "down3 = BatchNormalization()(down3)\n",
    "down3 = Activation('relu')(down3)\n",
    "down3_pool = MaxPooling2D((2, 2), strides=(2, 2))(down3)\n",
    "# 16\n",
    "\n",
    "down4 = Conv2D(512, (3, 3), padding='same')(down3_pool)\n",
    "down4 = BatchNormalization()(down4)\n",
    "down4 = Activation('relu')(down4)\n",
    "down4 = Conv2D(512, (3, 3), padding='same')(down4)\n",
    "down4 = BatchNormalization()(down4)\n",
    "down4 = Activation('relu')(down4)\n",
    "down4_pool = MaxPooling2D((2, 2), strides=(2, 2))(down4)\n",
    "# 8\n",
    "\n",
    "center = Conv2D(1024, (3, 3), padding='same')(down4_pool)\n",
    "center = BatchNormalization()(center)\n",
    "center = Activation('relu')(center)\n",
    "center = Conv2D(1024, (3, 3), padding='same')(center)\n",
    "center = BatchNormalization()(center)\n",
    "center = Activation('relu')(center)\n",
    "# center\n",
    "\n",
    "up4 = UpSampling2D((2, 2))(center)\n",
    "up4 = concatenate([down4, up4], axis=3)\n",
    "up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "up4 = BatchNormalization()(up4)\n",
    "up4 = Activation('relu')(up4)\n",
    "up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "up4 = BatchNormalization()(up4)\n",
    "up4 = Activation('relu')(up4)\n",
    "up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "up4 = BatchNormalization()(up4)\n",
    "up4 = Activation('relu')(up4)\n",
    "# 16\n",
    "\n",
    "up3 = UpSampling2D((2, 2))(up4)\n",
    "up3 = concatenate([down3, up3], axis=3)\n",
    "up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "up3 = BatchNormalization()(up3)\n",
    "up3 = Activation('relu')(up3)\n",
    "up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "up3 = BatchNormalization()(up3)\n",
    "up3 = Activation('relu')(up3)\n",
    "up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "up3 = BatchNormalization()(up3)\n",
    "up3 = Activation('relu')(up3)\n",
    "# 32\n",
    "\n",
    "up2 = UpSampling2D((2, 2))(up3)\n",
    "up2 = concatenate([down2, up2], axis=3)\n",
    "up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "up2 = BatchNormalization()(up2)\n",
    "up2 = Activation('relu')(up2)\n",
    "up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "up2 = BatchNormalization()(up2)\n",
    "up2 = Activation('relu')(up2)\n",
    "up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "up2 = BatchNormalization()(up2)\n",
    "up2 = Activation('relu')(up2)\n",
    "# 64\n",
    "\n",
    "up1 = UpSampling2D((2, 2))(up2)\n",
    "up1 = concatenate([down1, up1], axis=3)\n",
    "up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "up1 = BatchNormalization()(up1)\n",
    "up1 = Activation('relu')(up1)\n",
    "up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "up1 = BatchNormalization()(up1)\n",
    "up1 = Activation('relu')(up1)\n",
    "up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "up1 = BatchNormalization()(up1)\n",
    "up1 = Activation('relu')(up1)\n",
    "# 128\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid')(up1)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile Model\n",
    "\n",
    "optimizer = tf.train.RMSPropOptimizer(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizer, \n",
    "    loss=\"binary_crossentropy\", \n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use for development to run it faster\n",
    "if FAST_RUN:\n",
    "    df = df.sample(n=10000).reset_index().drop(columns=[\"index\"]) # after reset index dataframe will have one more column call index\n",
    "    \n",
    "if FAST_PREDICTION:\n",
    "    sub_df = sub_df.sample(n=100).reset_index().drop(columns=[\"index\"]) # after reset index dataframe will have one more column call index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split train and validate data\n",
    "\n",
    "train_df, validate_df = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator\n",
    "\n",
    "def get_image(image_name):\n",
    "    img = imread('../input/train_v2/'+image_name)[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (TARGET_WIDTH, TARGET_HEIGHT), mode='constant', preserve_range=True)\n",
    "    return img\n",
    "    \n",
    "def get_mask(code):\n",
    "    img = rle_decode(code)\n",
    "    img = resize(img, (TARGET_WIDTH, TARGET_HEIGHT, 1), mode='constant', preserve_range=True)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_generator(precess_batch_size, data_df):\n",
    "    while True:\n",
    "        for k, group_df in data_df.groupby(np.arange(data_df.shape[0])//precess_batch_size):\n",
    "            imgs = []\n",
    "            labels = []\n",
    "            for index, row in group_df.iterrows():\n",
    "                # images\n",
    "                original_img = get_image(row.ImageId) / 255.0\n",
    "                # masks\n",
    "                mask = get_mask(row.EncodedPixels) / 255.0\n",
    "                \n",
    "                imgs.append(original_img)\n",
    "                labels.append(mask)\n",
    "                \n",
    "            imgs = np.array(imgs)\n",
    "            labels = np.array(labels)\n",
    "            yield imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = create_image_generator(batch_size, train_df)\n",
    "validate_generator = create_image_generator(batch_size, validate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit Model\n",
    "\n",
    "train_steps=np.ceil(float(train_df.shape[0]) / float(batch_size)).astype(int)\n",
    "validate_steps=np.ceil(float(validate_df.shape[0]) / float(batch_size)).astype(int)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=validate_generator,\n",
    "    validation_steps=validate_steps,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction\n",
    "\n",
    "def get_test_image(image_name):\n",
    "    img = imread('../input/test_v2/'+image_name)[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (TARGET_WIDTH, TARGET_HEIGHT), mode='constant', preserve_range=True)\n",
    "    return img\n",
    "    \n",
    "def create_test_generator(precess_batch_size):\n",
    "    while True:\n",
    "        for k, ix in sub_df.groupby(np.arange(sub_df.shape[0])//precess_batch_size):\n",
    "            imgs = []\n",
    "            labels = []\n",
    "            for index, row in ix.iterrows():\n",
    "                original_img = get_test_image(row.ImageId) / 255.0\n",
    "                imgs.append(original_img)\n",
    "                \n",
    "            imgs = np.array(imgs)\n",
    "            yield imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = create_test_generator(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_steps = np.ceil(float(sub_df.shape[0]) / float(batch_size)).astype(int)\n",
    "predict_mask = model.predict_generator(test_generator, steps=test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See prediction\n",
    "\n",
    "fig=plt.figure(figsize=(16, 8))\n",
    "for index, row in sub_df.head(6).iterrows():\n",
    "    origin_image = imread('../input/test_v2/'+row.ImageId)\n",
    "    predicted_image = resize(predict_mask[index], image_shape).reshape(IMG_WIDTH, IMG_HEIGHT) * 255\n",
    "    plt.subplot(3, 4, 2*index+1)\n",
    "    plt.imshow(origin_image)\n",
    "    plt.subplot(3, 4, 2*index+2)\n",
    "    plt.imshow(predicted_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submissimon\n",
    "\n",
    "for index, row in sub_df.iterrows():\n",
    "    predict = predict_mask[index]\n",
    "    resized_predict =  resize(predict, (IMG_WIDTH, IMG_HEIGHT)) * 255\n",
    "    mask = resized_predict > 0.5\n",
    "    sub_df.at[index,'EncodedPixels'] = rle_encode(mask)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
